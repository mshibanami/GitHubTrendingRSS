<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>GitHub Cuda Monthly Trending</title>
    <description>Monthly Trending of Cuda in GitHub</description>
    <pubDate>Sat, 27 Sep 2025 01:51:57 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>nerfstudio-project/gsplat</title>
      <link>https://github.com/nerfstudio-project/gsplat</link>
      <description>&lt;p&gt;CUDA accelerated rasterization of gaussian splatting&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>flashinfer-ai/flashinfer</title>
      <link>https://github.com/flashinfer-ai/flashinfer</link>
      <description>&lt;p&gt;FlashInfer: Kernel Library for LLM Serving&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>karpathy/llm.c</title>
      <link>https://github.com/karpathy/llm.c</link>
      <description>&lt;p&gt;LLM training in simple, raw C/CUDA&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/nccl-tests</title>
      <link>https://github.com/NVIDIA/nccl-tests</link>
      <description>&lt;p&gt;NCCL Tests&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>HazyResearch/ThunderKittens</title>
      <link>https://github.com/HazyResearch/ThunderKittens</link>
      <description>&lt;p&gt;Tile primitives for speedy kernels&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Dao-AILab/causal-conv1d</title>
      <link>https://github.com/Dao-AILab/causal-conv1d</link>
      <description>&lt;p&gt;Causal depthwise conv1d in CUDA, with a PyTorch interface&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>HenryHuYu/DiffPhysDrone</title>
      <link>https://github.com/HenryHuYu/DiffPhysDrone</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>deepseek-ai/DeepGEMM</title>
      <link>https://github.com/deepseek-ai/DeepGEMM</link>
      <description>&lt;p&gt;DeepGEMM: clean and efficient FP8 GEMM kernels with fine-grained scaling&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>thu-ml/SageAttention</title>
      <link>https://github.com/thu-ml/SageAttention</link>
      <description>&lt;p&gt;Quantized Attention achieves speedup of 2-5x and 3-11x compared to FlashAttention and xformers, without lossing end-to-end metrics across language, image, and video models.&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>rahul-goel/fused-ssim</title>
      <link>https://github.com/rahul-goel/fused-ssim</link>
      <description>&lt;p&gt;Lightning fast differentiable SSIM.&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>deepseek-ai/DeepEP</title>
      <link>https://github.com/deepseek-ai/DeepEP</link>
      <description>&lt;p&gt;DeepEP: an efficient expert-parallel communication library&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>thu-ml/SpargeAttn</title>
      <link>https://github.com/thu-ml/SpargeAttn</link>
      <description>&lt;p&gt;SpargeAttention: A training-free sparse attention that can accelerate any model inference.&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/CUDALibrarySamples</title>
      <link>https://github.com/NVIDIA/CUDALibrarySamples</link>
      <description>&lt;p&gt;CUDA Library Samples&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>Infatoshi/cuda-course</title>
      <link>https://github.com/Infatoshi/cuda-course</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
    <item>
      <title>rapidsai/cuvs</title>
      <link>https://github.com/rapidsai/cuvs</link>
      <description>&lt;p&gt;cuVS - a library for vector search and clustering on the GPU&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
  </channel>
</rss>
